{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020\n",
    "\n",
    "April 6, 2020 : Major edit to store files in order of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack\n",
    "from ipywidgets import interact, interact_manual,fixed, SelectMultiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 13357 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4. + 1e-8) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_get_samples(df,key):\n",
    "    '''\n",
    "    Extract array of samples from the DataFrame with images\n",
    "    Images are of two types:\n",
    "    1. *_gen have shape (64,1,128,128)\n",
    "    2. *_input have shape (64,16384)\n",
    "    '''\n",
    "    \n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "    assert key in keys,\"Given key %s is not the the list of keys %s\"%(key,keys)\n",
    "    \n",
    "    lst=df[df.type==key]['image'].values\n",
    "    \n",
    "    if key.endswith('input'):\n",
    "        size=np.int(np.sqrt(lst[0].shape[-1])) ### Extract size of images (=128)\n",
    "        samples=np.array([ii[0,:].reshape(size,size) for ii in lst])\n",
    "    else : \n",
    "        samples=np.array([ii[0,0,:,:] for ii in lst])\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200421_055139_exagan/dump_outs/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200316_112134_exagan'\n",
    "fldr_name='20200406_080207_exagan_with_mcr'\n",
    "fldr_name='20200407_093719_exagan_no_mcr'\n",
    "fldr_name='20200409_084926_exagan_no_mcr'\n",
    "fldr_name='20200409_083646_exagan_with_mcr'\n",
    "fldr_name='20200413_095840_exagan'\n",
    "\n",
    "fldr_name='20200421_055139_exagan'\n",
    "fldr_name='20200421_130545_exagan'\n",
    "fldr_name='20200421_132207_exagan'\n",
    "\n",
    "\n",
    "### Code for set of runs\n",
    "# f_list=['20200401_125919_exagan_0.1_1','20200401_130321_exagan_0.1_4',\n",
    "#         '20200401_130907_exagan_0.3_1','20200401_130646_exagan_0.3_4']\n",
    "# fldr_name=f_list[0]\n",
    "\n",
    "\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning the number of files is very large. Possibility of memory overload\n",
      "Warning the number of files is very large. Possibility of memory overload\n",
      "train_gen 2220\n",
      "train_input 2220\n",
      "val_gen 248\n",
      "val_input 248\n",
      "Sorting done\n",
      "Extraction done\n",
      "Time for Sorting 20.03162717819214\n",
      "Time for Reading images 184.31417989730835\n",
      "(4936, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Get images files and .npy arrays for each image in dump_outs folder\n",
    "files_dict={}\n",
    "keys=['train_gen','train_input','val_gen','val_input']\n",
    "file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "for key,file_strg in zip(keys,file_strg_lst):\n",
    "    files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "    if files_dict[key].shape[0]>1000 : \n",
    "        print('Warning the number of files is very large. Possibility of memory overload')\n",
    "\n",
    "df_files=pd.DataFrame([])\n",
    "dict1={}\n",
    "t1=time.time()\n",
    "### First get sorted Dataframe with file names\n",
    "for key in keys: \n",
    "    files_arr=files_dict[key]  # Get array of files\n",
    "    print(key,len(files_arr))\n",
    "    for fname in files_arr:\n",
    "        ### Extract the Epoch number and step number from the file name\n",
    "        dict1['type']=key\n",
    "        dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "        dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "        dict1['fname']=fname\n",
    "        \n",
    "        df_files=df_files.append(dict1,ignore_index=True)\n",
    "## Sort values\n",
    "df_files=df_files.sort_values(by=['type','epoch','step']).reset_index(drop=True)\n",
    "# df_files\n",
    "print(\"Sorting done\")\n",
    "\n",
    "t2=time.time()\n",
    "### Then read images one by one into a numpy array and create a new DataFrame\n",
    "sorted_fnames=df_files.fname.values\n",
    "### Read images one by one. This is time-consuming.\n",
    "### Deliberately kept as list because some of the input arrays have different dimensions, causing creation of array of arrays in some cases\n",
    "images=[np.load(fname) for fname in sorted_fnames]  \n",
    "\n",
    "##### Create new Dataframe with sorted images\n",
    "df_full=pd.DataFrame([])\n",
    "df_full['image']=images\n",
    "t3=time.time()\n",
    "for col in ['epoch','step','type','fname']: df_full[col]=df_files[col].values\n",
    "print(\"Extraction done\")\n",
    "\n",
    "print(\"Time for Sorting\",t2-t1)\n",
    "print(\"Time for Reading images\",t3-t2)\n",
    "\n",
    "df=df_full.copy()\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Slice DataFrame before getting samples. Get 1 images per epochs (choose the last step)\n",
    "\n",
    "def f_filter_epoch(df_input):\n",
    "    '''\n",
    "    Get just the last stored step image for each epoch\n",
    "    '''\n",
    "    df_output=pd.DataFrame([])\n",
    "    for key in ['train_gen','train_input','val_gen','val_input']: \n",
    "        ### For each type of images, get list of epochs\n",
    "        df1=df_input[df_input.type==key]\n",
    "        epochs=np.unique(df1.epoch.values).astype(int)\n",
    "        for epoch in epochs:### Extract the last step in each epoch\n",
    "            df2=df1[df1.epoch==epoch]\n",
    "            df_output=df_output.append(df2.iloc[-1])  \n",
    "    \n",
    "    return df_output.reset_index(drop=True)\n",
    "\n",
    "df=f_filter_epoch(df_full)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 128, 128)\n",
      "(60, 128, 128)\n",
      "(60, 128, 128)\n",
      "(60, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "samples1=f_get_samples(df,'train_input')\n",
    "print(samples1.shape)\n",
    "samples2=f_get_samples(df,'val_gen')\n",
    "print(samples2.shape)\n",
    "\n",
    "samples3=f_get_samples(df,'train_gen')\n",
    "print(samples3.shape)\n",
    "samples4=f_get_samples(df,'val_input')\n",
    "print(samples4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the region without very high pixel values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34ffa105b554f6ea114f78364074ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f_plot_max_values(samples,cutoff=0.994):\n",
    "    '''\n",
    "    Make a plot of max values of images of a given set of sample images\n",
    "    cutoff used to discard high values\n",
    "    '''\n",
    "    ### Get max pixel values of images\n",
    "    max_values=np.array([np.max(i) for i in samples])\n",
    "    ### Less than cutoff\n",
    "    lesser_idx=np.where(max_values<cutoff)[0]\n",
    "    higher_idx=np.where(max_values>=cutoff)[0]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(lesser_idx,max_values[lesser_idx],linestyle='',marker='*',color='r')\n",
    "    plt.plot(higher_idx,max_values[higher_idx],linestyle='',marker='D',color='b')\n",
    "\n",
    "    plt.axhline(y=cutoff,linestyle='--',color='k')\n",
    "    plt.ylim(0.9,1.0)\n",
    "    \n",
    "f_plot_max_values(samples2,0.9945)\n",
    "# f_plot_max_values(samples4,0.992)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_pixel_intensity(img_arr,bins=25,label='validation',mode='avg',normalize=False,log_scale=True,plot=True):\n",
    "    '''\n",
    "    Module to compute and plot histogram for pixel intensity of images\n",
    "    Has 2 modes : simple and avg\n",
    "        simple mode: No errors. Just flatten the input image array and compute histogram of full data\n",
    "        avg mode(Default) : \n",
    "            - Compute histogram for each image in the image array\n",
    "            - Compute errors across each histogram \n",
    "    '''\n",
    "    \n",
    "    norm=normalize # Whether to normalize the histogram\n",
    "    \n",
    "    def f_batch_histogram(img_arr,bins,norm):\n",
    "        ''' Compute histogram statistics for a batch of images'''\n",
    "        \n",
    "        ## Extracting the range. This is important to ensure that the different histograms are compared correctly\n",
    "        ulim,llim=np.max(img_arr),np.min(img_arr)\n",
    "        ### array of histogram of each image\n",
    "        hist_arr=np.array([np.histogram(arr.flatten(), bins=bins, range=(llim,ulim), density=norm) for arr in img_arr]) ## range is important\n",
    "        hist=np.stack(hist_arr[:,0]) # First element is histogram array\n",
    "        print(hist.shape)\n",
    "        bin_list=np.stack(hist_arr[:,1]) # Second element is bin value \n",
    "        ### Compute statistics over histograms of individual images\n",
    "        mean,err=np.mean(hist,axis=0),np.std(hist,axis=0)/np.sqrt(hist.shape[0])\n",
    "        bin_edges=bin_list[0]\n",
    "        centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "        return mean,err,centers\n",
    "    \n",
    "    if plot: \n",
    "        plt.figure()\n",
    "        plt.xlabel('Pixel value')\n",
    "        plt.ylabel('Counts')\n",
    "        plt.title('Pixel Intensity Histogram')\n",
    "\n",
    "        if log_scale: plt.yscale('log')\n",
    "    \n",
    "    if mode=='simple':\n",
    "        hist, bin_edges = np.histogram(img_arr.flatten(), bins=25, density=norm)\n",
    "        centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        if plot: plt.errorbar(centers, hist, fmt='o-', label=label)\n",
    "        return hist,None\n",
    "    \n",
    "    elif mode=='avg': \n",
    "        ### Compute histogram for each image. \n",
    "        mean,err,centers=f_batch_histogram(img_arr,bins,norm)\n",
    "\n",
    "        if plot: plt.errorbar(centers,mean,yerr=err,fmt='o-',label=label)  \n",
    "        return mean,err\n",
    "\n",
    "# _,_=f_pixel_intensity(f_invtransform(samples2),bins=100,label='validation',mode='simple',normalize=False,log_scale=True,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_pixel_intensity(arr,label,start,end,normalize=True,log_scale=True,rescale=True):\n",
    "    '''\n",
    "    Module to plot pixel intensity with options for normalization, log-scal, and rescale\n",
    "    Rescale converts image pixel values from (-1,1) to the original pixel range\n",
    "    '''\n",
    "    try :\n",
    "        sliced_arr=arr[start:end]\n",
    "        if sliced_arr.shape[0]<1:\n",
    "            print('Input indices %s %s are invalid.\\nUsing full array'%(start,end))\n",
    "            start0,end=0,'end'\n",
    "            sliced_arr=arr[:]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if rescale: ### Converting from pixel intensity range (-1,1) to original range\n",
    "        sliced_arr=f_invtransform(sliced_arr)\n",
    "    print('Array size used',sliced_arr.shape)\n",
    "    \n",
    "    f_pixel_intensity(sliced_arr,label=label+': {0}-{1}'.format(str(start),str(end)),normalize=normalize,mode='simple')\n",
    "\n",
    "# f_widget_pixel_intensity(samples2,'s2',0,None,True,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401c189046064912b0cea1888b0b8f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='start', options=(0, 10, 20, 30, 40, 50, 60, 70, 80, 90), value=0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_pixel_intensity(arr, label, start, end, normalize=True, log_scale=True, rescale=True)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(f_widget_pixel_intensity,arr=fixed(samples2),label=fixed('s1'),start=np.arange(0,100,10),end=np.arange(0,100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact_manual(f_widget_pixel_intensity,arr=[samples1,samples2],label=['s1','s2'],start=np.arange(0,100,10),end=np.arange(0,100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_compare_pixel_intensity([samples1,samples2,samples3,samples4],label_lst=['s1','s2','s3','s4'],normalize=False,log_scale=True, mode='avg',bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare pixel intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_compare_pixel_intensity(sample_names,sample_dict,rescale=True,log_scale=True,bins=25,mode='avg',normalize=True):\n",
    "    \n",
    "    img_list=[sample_dict[key] for key in sample_names]\n",
    "    label_list=list(sample_names)\n",
    "    \n",
    "    if rescale: \n",
    "        for count,img in enumerate(img_list):\n",
    "            img_list[count]=f_invtransform(img)\n",
    "    \n",
    "    f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins)\n",
    "    \n",
    "# f_widget_compare_pixel_intensity(dict_samples.keys(),dict_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_sample_epochs(samples):\n",
    "    \n",
    "    size=samples.shape[0]\n",
    "    img_list,labels_list=[],[]\n",
    "    for i in range(0,size,10):\n",
    "        i1,i2=i,i+10\n",
    "        img_list.append(samples[i1:i2])\n",
    "#         img_list.append(f_invtransform(samples[i1:i2]))\n",
    "\n",
    "        labels_list.append('%s:%s'%(str(i1),str(i2)))\n",
    "    img_list.append(samples)\n",
    "    labels_list.append('0:end')\n",
    "    \n",
    "    return img_list,labels_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0146214a8639446b9f356f3fafdd9225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('0:10', '10:20', '20:30', '30:40', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare_pixel_intensity(sample_names, sample_dict, rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list,label_list=f_get_sample_epochs(samples2)\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "interact_manual(f_widget_compare_pixel_intensity,sample_dict=fixed(dict_samples),sample_names=SelectMultiple(options=dict_samples.keys()),bins=np.arange(10,201,20),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different sample sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0103b1a8dc48c38cb47ac86af012b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('s1', 's2', 's3', 's4'), value=()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare_pixel_intensity(sample_names, sample_dict, rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_samples={'s1':samples1, 's2':samples2[10:30],\n",
    "              's3':samples3, 's4':samples4}\n",
    "interact_manual(f_widget_compare_pixel_intensity,sample_dict=fixed(dict_samples),sample_names=SelectMultiple(options=dict_samples.keys()),bins=np.arange(10,201,20),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pixel_intensity(f_invtransform(samples2),normalize=False)\n",
    "# f_compare_pixel_intensity([samples1,samples2,samples3,samples4],label_lst=['s1','s2','s3','s4'],normalize=False,log_scale=True, mode='avg',bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grid of intensity histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_plot_intensity_grid(samples2[40:80][::5],cols=6)\n",
    "# f_plot_intensity_grid(f_invtransform(samples2[22:52][::3]),cols=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_compute_spectrum(samples1)\n",
    "# f_compute_spectrum(f_invtransform(samples2[51:80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start,end=22,52\n",
    "# start,end=23,33\n",
    "f_compare_spectrum(samples4[start:end],samples2[start:end],label1='input',label2='generated')\n",
    "f_compare_spectrum(f_invtransform(samples4[start:end]),f_invtransform(samples2[start:end]),label1='input',label2='generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end=33,None\n",
    "f_compare_spectrum(samples4[start:end],samples2[start:end],label1='input',label2='generated')\n",
    "f_compare_spectrum(f_invtransform(samples4[start:end]),f_invtransform(samples2[start:end]),label1='input',label2='generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
