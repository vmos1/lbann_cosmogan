{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020 \\\n",
    "April 6, 2020 : Major edit to store files in order of epochs \\\n",
    "April 21, 2020: Major edit, added jupyter widgets to compare pixel intensity plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack\n",
    "# from ipywidgets import interact, interact_manual,fixed, SelectMultiple, IntText, IntSlider, FloatSlider,SelectionSlider,BoundedIntText\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 14763 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4. + 1e-8) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_samples(df,key):\n",
    "    '''\n",
    "    Extract array of samples from the DataFrame with images\n",
    "    Images are of two types:\n",
    "    1. *_gen have shape (64,1,128,128)\n",
    "    2. *_input have shape (64,16384)\n",
    "    '''\n",
    "    \n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "    assert key in keys,\"Given key %s is not the the list of keys %s\"%(key,keys)\n",
    "    \n",
    "    lst=df[df.type==key]['image'].values\n",
    "    \n",
    "    if key.endswith('input'):\n",
    "        size=np.int(np.sqrt(lst[0].shape[-1])) ### Extract size of images (=128)\n",
    "        samples=np.array([ii[0,:].reshape(size,size) for ii in lst])\n",
    "    else : \n",
    "        samples=np.array([ii[0,0,:,:] for ii in lst])\n",
    "    \n",
    "    return samples\n",
    "\n",
    "\n",
    "def f_filter_epoch(df_input,num_sliced=1):\n",
    "    '''\n",
    "    Get just the last few stored step images for each epoch\n",
    "    '''\n",
    "    print('Extracting last %s steps of each epoch'%(num_sliced))\n",
    "    df_output=pd.DataFrame([])\n",
    "    for key in ['train_gen','train_input','val_gen','val_input']: \n",
    "        ### For each type of images, get list of epochs\n",
    "        df1=df_input[df_input.type==key]\n",
    "        epochs=np.unique(df1.epoch.values).astype(int)\n",
    "\n",
    "        for epoch in epochs:### Extract the last few steps in each epoch\n",
    "            df2=df1[df1.epoch==epoch]\n",
    "            df_output=df_output.append(df2.iloc[-num_sliced:])  \n",
    "    \n",
    "    return df_output.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200506_121613_exagan_200k_samples/dump_outs/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200316_112134_exagan'\n",
    "fldr_name='20200406_080207_exagan_with_mcr'\n",
    "fldr_name='20200407_093719_exagan_no_mcr'\n",
    "fldr_name='20200409_084926_exagan_no_mcr'\n",
    "fldr_name='20200409_083646_exagan_with_mcr'\n",
    "fldr_name='20200413_095840_exagan'\n",
    "\n",
    "fldr_name='20200421_055139_exagan'\n",
    "fldr_name='20200421_130545_exagan'\n",
    "fldr_name='20200423_071820_exagan_v0_works'\n",
    "fldr_name='20200423_122631_exagan_modified_paddding'\n",
    "fldr_name='20200424_083456_exagan_modified_padding_2'\n",
    "fldr_name='20200506_121613_exagan_200k_samples'\n",
    "### Code for set of runs\n",
    "# f_list=['20200401_125919_exagan_0.1_1','20200401_130321_exagan_0.1_4',\n",
    "#         '20200401_130907_exagan_0.3_1','20200401_130646_exagan_0.3_4']\n",
    "# fldr_name=f_list[0]\n",
    "\n",
    "\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "## Extracted generated image from keras cosmogan code\n",
    "\n",
    "fname='/global/cfs/cdirs/dasrepo/vpa/cosmogan/data/computed_data/exagan1/run1/gen_imgs.npy'\n",
    "a1=np.load(fname)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen 962\n",
      "train_input 962\n",
      "val_gen 241\n",
      "val_input 241\n",
      "Sorting done\n",
      "Time for Sorting 8.824666500091553\n",
      "Extracting last 2 steps of each epoch\n",
      "Extraction done\n",
      "Time for filtering 0.6494908332824707\n",
      "Time for Reading images 22.71859884262085\n",
      "(480, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Get images files and .npy arrays for each image in dump_outs folder\n",
    "files_dict={}\n",
    "keys=['train_gen','train_input','val_gen','val_input']\n",
    "file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "for key,file_strg in zip(keys,file_strg_lst):\n",
    "    files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "    if files_dict[key].shape[0]>1000 : \n",
    "        print('Warning the number of files is very large. Possibility of memory overload')\n",
    "\n",
    "df_files=pd.DataFrame([])\n",
    "dict1={}\n",
    "t1=time.time()\n",
    "### First get sorted Dataframe with file names\n",
    "for key in keys: \n",
    "    files_arr=files_dict[key]  # Get array of files\n",
    "    print(key,len(files_arr))\n",
    "    for fname in files_arr:\n",
    "        ### Extract the Epoch number and step number from the file name\n",
    "        dict1['type']=key\n",
    "        dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "        dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "        dict1['fname']=fname\n",
    "        \n",
    "        df_files=df_files.append(dict1,ignore_index=True)\n",
    "## Sort values\n",
    "df_files=df_files.sort_values(by=['type','epoch','step']).reset_index(drop=True)\n",
    "# df_files\n",
    "print(\"Sorting done\")\n",
    "t2=time.time()\n",
    "print(\"Time for Sorting\",t2-t1)\n",
    "\n",
    "#############################################################\n",
    "### Slice out rows to keep only the last 2 steps for each epoch.\n",
    "df_files=f_filter_epoch(df_files,num_sliced=2)\n",
    "t3=time.time()\n",
    "\n",
    "### Then read images one by one into a numpy array and create a new DataFrame\n",
    "sorted_fnames=df_files.fname.values\n",
    "### Read images one by one. This is time-consuming.\n",
    "### Deliberately kept as list because some of the input arrays have different dimensions, causing creation of array of arrays in some cases\n",
    "images=[np.load(fname) for fname in sorted_fnames]  \n",
    "\n",
    "##### Create new Dataframe with sorted images\n",
    "df_full=pd.DataFrame([])\n",
    "df_full['image']=images\n",
    "t4=time.time()\n",
    "for col in ['epoch','step','type','fname']: df_full[col]=df_files[col].values\n",
    "    \n",
    "print(\"Extraction done\")\n",
    "print(\"Time for filtering\",t3-t2)\n",
    "print(\"Time for Reading images\",t4-t3)\n",
    "df=df_full.copy()\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting last 1 steps of each epoch\n"
     ]
    }
   ],
   "source": [
    "### Filter to keep just one image per epoch\n",
    "df=f_filter_epoch(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fname</th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>2624.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>3854.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>3936.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>5166.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>5248.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>6478.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>6560.0</td>\n",
       "      <td>train_gen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch                                              fname    step       type\n",
       "0    0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  1230.0  train_gen\n",
       "1    0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  1312.0  train_gen\n",
       "2    1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  2542.0  train_gen\n",
       "3    1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  2624.0  train_gen\n",
       "4    2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  3854.0  train_gen\n",
       "5    2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  3936.0  train_gen\n",
       "6    3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  5166.0  train_gen\n",
       "7    3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  5248.0  train_gen\n",
       "8    4.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  6478.0  train_gen\n",
       "9    4.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  6560.0  train_gen"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 128, 128)\n",
      "(60, 128, 128)\n",
      "(60, 128, 128)\n",
      "(60, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "samples1=f_get_samples(df,'train_input')\n",
    "print(samples1.shape)\n",
    "samples2=f_get_samples(df,'val_gen')\n",
    "print(samples2.shape)\n",
    "\n",
    "samples3=f_get_samples(df,'train_gen')\n",
    "print(samples3.shape)\n",
    "samples4=f_get_samples(df,'val_input')\n",
    "print(samples4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the region without very high pixel values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd68378511ac430ba77d99d054edb972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f_plot_max_values(samples,cutoff=0.994):\n",
    "    '''\n",
    "    Make a plot of max values of images of a given set of sample images\n",
    "    cutoff used to discard high values\n",
    "    '''\n",
    "    ### Get max pixel values of images\n",
    "    max_values=np.array([np.max(i) for i in samples])\n",
    "    ### Less than cutoff\n",
    "    lesser_idx=np.where(max_values<cutoff)[0]\n",
    "    higher_idx=np.where(max_values>=cutoff)[0]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(lesser_idx,max_values[lesser_idx],linestyle='',marker='*',color='r')\n",
    "    plt.plot(higher_idx,max_values[higher_idx],linestyle='',marker='D',color='b')\n",
    "\n",
    "    plt.axhline(y=cutoff,linestyle='--',color='k')\n",
    "    plt.ylim(0.9,1.0)\n",
    "    \n",
    "f_plot_max_values(samples2,0.9966)  ### The full dataset has a max value of just over 0.9966\n",
    "# f_plot_max_values(samples2,0.9945)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pixel_intensity(samples2,'s2',normalize=True,mode='simple',bins=50)\n",
    "# f_compare_pixel_intensity([samples2[20:60],samples4,['s2','s4'],normalize=normalize,log_scale=log_scale, mode=mode,bins=bins)\n",
    "# f_compute_spectrum(samples2)\n",
    "# f_compare_spectrum([samples2[20:60],samples4],['s2','s4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_individual(arr,label,idx_range=(0,50),Fig_type='pixel',normalize=True,log_scale=True,rescale=True,mode='simple'):\n",
    "    '''\n",
    "    Module to plot pixel intensity or power spectrum for a given sample set of images\n",
    "    Options for normalization, log-scal, and rescale\n",
    "    Rescale converts image pixel values from (-1,1) to the original pixel range\n",
    "    2 Fig_type: pixel-> pixel intensity and spectrum -> power spectrum\n",
    "    '''\n",
    "    \n",
    "    start,end=idx_range[0],idx_range[1]\n",
    "    print('Index Range %s - %s'%(start,end))\n",
    "    try :\n",
    "        sliced_arr=arr[start:end]\n",
    "        if sliced_arr.shape[0]<1:\n",
    "            print('Input indices %s %s are invalid.\\nUsing full array'%(start,end))\n",
    "            start0,end=0,'end'\n",
    "            sliced_arr=arr[:]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if rescale: ### Converting from pixel intensity range (-1,1) to original range\n",
    "        sliced_arr=f_invtransform(sliced_arr)\n",
    "    print('Array size used',sliced_arr.shape)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_pixel_intensity(sliced_arr,label=label+': {0}-{1}'.format(str(start),str(end)),normalize=normalize,log_scale=log_scale,mode=mode)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compute_spectrum(sliced_arr,label=label+': {0}-{1}'.format(str(start),str(end)),log_scale=log_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba843bb4da8f4796833d9d2ed81c49fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(30, 70), description='idx_range', max=200), ToggleButtons(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_individual(arr, label, idx_range=(0, 50), Fig_type='pixel', normalize=True, log_scale=True, rescale=True, mode='simple')>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(f_widget_individual,arr=fixed(samples2),label=fixed('s1'),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),mode=['avg','simple'],\n",
    "                idx_range=IntRangeSlider(value=(30,70),min=0,max=200,step=1),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_compare(sample_names,sample_dict,Fig_type='pixel',rescale=True,log_scale=True,bins=25,mode='avg',normalize=True):\n",
    "    '''\n",
    "    Module to make widget plots for pixel intensity or spectrum comparison for multiple sample sets\n",
    "    '''\n",
    "    img_list=[sample_dict[key] for key in sample_names]\n",
    "    label_list=list(sample_names)\n",
    "    \n",
    "    if rescale: \n",
    "        for count,img in enumerate(img_list):\n",
    "            img_list[count]=f_invtransform(img)\n",
    "    \n",
    "    assert Fig_type in ['pixel','spectrum'],\"Invalid mode %s\"%(mode)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compare_spectrum(img_lst=img_list,label_lst=label_list,log_scale=log_scale)\n",
    "        \n",
    "\n",
    "def f_get_sample_epochs(samples):\n",
    "    ''' Module to get list of different epoch slices. Useful to identify training stability'''\n",
    "    \n",
    "    size=samples.shape[0]\n",
    "    img_list,labels_list=[],[]\n",
    "    for i in range(0,size,10):\n",
    "        i1,i2=i,i+10\n",
    "        img_list.append(samples[i1:i2])\n",
    "#         img_list.append(f_invtransform(samples[i1:i2]))\n",
    "\n",
    "        labels_list.append('%s:%s'%(str(i1),str(i2)))\n",
    "    img_list.append(samples)\n",
    "    labels_list.append('0:end')\n",
    "    \n",
    "    return img_list,labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb90b32ee61d4ab5b6d3536939b138b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('0:10', '10:20', '20:30', '30:40', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare(sample_names, sample_dict, Fig_type='pixel', rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list,labels_list=f_get_sample_epochs(samples3)\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "\n",
    "### Compare with input\n",
    "dict_samples['s4']=samples4\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different sample sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfa22c905e0490f904c95acc4780757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('s1', 's2', 's3', 's4'), value=()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare(sample_names, sample_dict, Fig_type='pixel', rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_samples={'s1':samples1, 's2':samples2[35:60],\n",
    "              's3':samples3[30:60], 's4':samples4}\n",
    "\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),\n",
    "                bins=SelectionSlider(options=np.arange(10,200,10),value=50),\n",
    "                mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grid of intensity histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_plot_intensity_grid(samples2[40:80][::5],cols=6)\n",
    "# f_plot_intensity_grid(f_invtransform(samples2[22:52][::3]),cols=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
